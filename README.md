# FusedInf: Efficient Swapping of DNN Models for On-Demand Serverless Inference Services on the Edge

FusedInf efficiently swaps DNN models for on-demand serverless
inference services on the edge. FusedInf combines multiple
models into a single Direct Acyclic Graph (DAG) to efficiently
load the models into the GPU memory and make execution
faster.

_Demos and other helper modules will be added soon._